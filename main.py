from flask import Flask, request, jsonify
import pandas as pd
import joblib
import openai
import os
import re
import requests
from datetime import datetime

app = Flask(__name__)
openai.api_key = os.getenv("OPENAI_API_KEY")

# ì´ìƒ ê¸°ì¤€ ì„ê³„ê°’ ì„¤ì •
thresholds = {
    "Heartrate": (60, 100),
    "Breathrate": (12, 20),
    "SPO2": (95, 100),
    "Walking_steps": (3000, None),
    "Caloricexpenditure": (100, None)
}

# XGBoost ëª¨ë¸ ë¡œë“œ
model = joblib.load("/app/model/xgboost_emergency_model.pkl")

# ì´ìƒ ê°ì§€ í•¨ìˆ˜ (23:59ë§Œ ëˆ„ì  ê¸°ì¤€ íŒë‹¨ í¬í•¨)
def detect_abnormal_features(data, thresholds, timestamp_str):
    abnormal = {}

    try:
        timestamp = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M")
    except Exception:
        timestamp = None

    for key, value in data.items():
        if key in ["Walking_steps", "Caloricexpenditure"]:
            if not (timestamp and timestamp.hour == 23 and timestamp.minute == 59):
                continue

        min_val, max_val = thresholds.get(key, (None, None))
        if min_val is not None and value < min_val:
            abnormal[key] = f"{value} â†“ (>= {min_val})"
        elif max_val is not None and value > max_val:
            abnormal[key] = f"{value} â†‘ (<= {max_val})"
    return abnormal

# ì¶œë ¥ ì •ë¦¬ í•¨ìˆ˜
def clean_output(text):
    text = re.sub(r"ì‚¬íšŒë³µì§€ì‚¬.+?ë‹¤[.]", "", text)
    text = re.sub(r"(\d+)\.\s*", r"\n\1. ", text)
    text = re.sub(r"\.+", ".", text)
    text = re.sub(r"\s+", " ", text).strip()
    if text.endswith("ë‹¤.ë‹¤."):
        text = text[:-3] + "ë‹¤."
    elif text.endswith("ë‹¤.") and len(text) > 2 and text[-3] == ".":
        text = text[:-1]
    return text

# ì˜ˆì¸¡ ì—”ë“œí¬ì¸íŠ¸
@app.route("/ai/predict", methods=["POST"])
def predict():
    try:
        data = request.get_json()

        # í•„ìˆ˜ í‚¤ í™•ì¸
        required_features = ["Heartrate", "Breathrate", "SPO2", "Walking_steps", "Caloricexpenditure"]
        elderly_id = data.get("elderlyId")
        timestamp_str = data.get("timestamp")

        if elderly_id is None:
            return jsonify({"error": "'elderlyId' is required."}), 400
        if timestamp_str is None:
            return jsonify({"error": "'timestamp' (e.g., '2025-05-14 23:59') is required."}), 400

        input_data = {}
        for feat in required_features:
            if feat not in data:
                return jsonify({"error": f"'{feat}' is required."}), 400
            try:
                input_data[feat] = float(data[feat])
            except ValueError:
                return jsonify({"error": f"'{feat}' must be a float."}), 400

        # ì˜ˆì¸¡ ìˆ˜í–‰
        input_df = pd.DataFrame([input_data])
        prob = model.predict_proba(input_df)[0][1]
        prediction = int(prob > 0.7)
        label_map = {0: "Non-Emergency (ì •ìƒ)", 1: "Emergency (ë¹„ì •ìƒ)"}

        result = {
            "elderlyId": elderly_id,
            "predictionLabel": label_map[prediction],
            "explanation": ""
        }

        # ë¹„ì •ìƒ ì‹œ ì„¤ëª… ìƒì„±
        if prediction == 1:
            abnormal_dict = detect_abnormal_features(input_data, thresholds, timestamp_str)
            abnormal_text = "\n".join([f"{k}: {v}" for k, v in abnormal_dict.items()])

            importances = model.feature_importances_
            feature_names = model.feature_names_in_
            important_features = sorted(zip(feature_names, importances), key=lambda x: x[1], reverse=True)
            important_feature_text = ", ".join([feat for feat, _ in important_features[:2]])

            feature_text = "\n".join([f"{key}: {input_data[key]}" for key in feature_names])

            system_prompt = (
                "ë‹¹ì‹ ì€ ë…ê±°ë…¸ì¸ì˜ ê±´ê°•ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤. "
                "ì•„ë˜ ìƒì²´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬íšŒë³µì§€ì‚¬ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ê±´ê°• ìƒíƒœë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³ , í•„ìš”í•œ ìƒí™œ ì¡°ì¹˜ë¥¼ ì•ˆë‚´í•´ì£¼ì„¸ìš”."
            )
            user_prompt = (
                f"ë…ê±°ë…¸ì¸ì˜ ê±´ê°• ë°ì´í„°:\n{feature_text}\n\n"
                f"ì´ìƒ ê°ì§€ í•­ëª©:\n{abnormal_text}\n\n"
                f"íŠ¹íˆ '{important_feature_text}' í•­ëª©ì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
            )

            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            result["explanation"] = clean_output(response.choices[0].message.content)
        else:
            result["explanation"] = "í™˜ì ìƒíƒœëŠ” ì •ìƒì…ë‹ˆë‹¤. ë³„ë„ì˜ ì¡°ì¹˜ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤."

        # ğŸ”„ ë°±ì—”ë“œë¡œ ê²°ê³¼ ì „ì†¡
        try:
            backend_url = "http://your-backend-server.com/api/save"  # âœ… ìˆ˜ì • í•„ìš”
            headers = {"Content-Type": "application/json"}
            backend_response = requests.post(backend_url, json=result, headers=headers)
            if backend_response.status_code != 200:
                print("âš ï¸ ë°±ì—”ë“œ ì‘ë‹µ ì‹¤íŒ¨:", backend_response.status_code, backend_response.text)
        except Exception as be:
            print("âš ï¸ ë°±ì—”ë“œ ì „ì†¡ ì˜ˆì™¸:", str(be))

        return jsonify(result)

    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=True)
